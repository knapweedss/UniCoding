{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f2e033",
   "metadata": {},
   "source": [
    "### Шаг 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de29834",
   "metadata": {},
   "source": [
    "Возьмем синсет fall.v.01 и извлечем списки лемм, относящихся к этому синсету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7b86e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9d0d5098",
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_exemplar = wn.synset('fall.v.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "78e7998d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fall_langs = []\n",
    "for lang in wn.langs():\n",
    "    if len(fall_exemplar.lemma_names(lang)) != 0:\n",
    "        fall_langs.append(fall_exemplar.lemma_names(lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "84ec95d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'أخمد'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fall_langs[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331fd8b6",
   "metadata": {},
   "source": [
    "### Шаг 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e3191",
   "metadata": {},
   "source": [
    "Для каждой леммы из каждого языка составим список синсетов, к которым она относится. Из этих синсетов выберем такие, к которым относится больше 5 лемм из нашего изначального списка "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ff331",
   "metadata": {},
   "source": [
    "Сначала попробуем для одного языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2e39a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('fall.v.01'), Synset('crash.v.01'), Synset('fall.v.12')]\n"
     ]
    }
   ],
   "source": [
    "a = str(fall_langs[0]).replace('[','').replace(']','').replace(',','').replace(\"'\", '')\n",
    "fall_synsets = wn.synsets('墜ちる', lang='jpn')\n",
    "                          \n",
    "print(fall_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087f45b3",
   "metadata": {},
   "source": [
    "Работает все это достаточно быстро, поэтому я подбирала подходящий язык для получения синсета просто итерацией до получения результата (мне показалось так  проще)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f578914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = sorted(wn.langs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b2f0741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "smth = []\n",
    "for i in fall_langs:\n",
    "    if len(i) > 5:  # берем только те синсеты, где больше 5 лемм\n",
    "        for k in i:  # если несколько лемм в списке, то подбираем для каждой из них\n",
    "            for d in dummy:\n",
    "                a = str(k).replace('[','').replace(']','').replace(',','').replace(\"'\", '')\n",
    "                dum = wn.synsets(a, lang=d)\n",
    "                if len(dum) > 0:\n",
    "                    result.append(dum)\n",
    "    else:\n",
    "        for d in dummy:\n",
    "            a = str(i).replace('[','').replace(']','').replace(',','').replace(\"'\", '')\n",
    "            dum = wn.synsets(a, lang=d)\n",
    "            if len(dum) > 0:\n",
    "                smth.append(dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "09a78c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc069f2",
   "metadata": {},
   "source": [
    "### Шаг  3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f1d8f",
   "metadata": {},
   "source": [
    "теперь строим ребра. Ребро между двумя синсетами будем ставьте в том случае, если хотя бы в одном языке есть хотя бы одна лемма, которая относится к ним обоим. Пусть граф будет взвешенным: вес ребра будет отражать количество лемм, относящихся к обоим узлам пары.\n",
    "\n",
    "NB! На этом шаге мы уже забываем про исходный список лемм из шага 1 (он нам нужен был только для отбора синсетов) и учитываем все леммы, относящиеся к отобранным узлам.\n",
    "\n",
    "Критерии: 0.5 балла - ребра, 0.5 балла - вес ребер\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3483c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d8d212ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "syns = []\n",
    "lems = []\n",
    "for synsets in result:\n",
    "    for s in synsets:\n",
    "        syns.append(s)\n",
    "        lems.append(s.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f3cca8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('decrease.v.01.decrease'),\n",
       " Lemma('decrease.v.01.diminish'),\n",
       " Lemma('decrease.v.01.lessen'),\n",
       " Lemma('decrease.v.01.fall')]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49af3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "df310abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph() # пустой граф\n",
    "G.add_node(1) # добавляем один узел\n",
    "G.add_nodes_from([2 ,3, 4, 5, 6]) # добавляем несколько узлов сразу\n",
    "\n",
    "G.remove_node(6) # удаляем узел номер 6\n",
    "\n",
    "# То, как мы обозначаем узлы (1, 2, 3 ...) -- это их id. Но вообще-то мы можем приклеить к ним и полноценные лейблы:\n",
    "G.add_node(1, label=\"node_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "314c978a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('sedate.v.01.sedate'),\n",
       " Lemma('sedate.v.01.calm'),\n",
       " Lemma('sedate.v.01.tranquilize'),\n",
       " Lemma('sedate.v.01.tranquillize'),\n",
       " Lemma('sedate.v.01.tranquillise')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[10][0].lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b340d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
